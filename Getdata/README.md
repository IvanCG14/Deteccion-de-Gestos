# üì∏ Hand Gesture Dataset Creator (Multi-Modal)

Sistema dual para la creaci√≥n de datasets de gestos de mano (Rock, Paper, Scissors). Permite capturar datos √∫nicamente visuales o sincronizarlos con biose√±ales del brazalete MYO Armband.

## üìã Tabla de Contenidos
- [Descripci√≥n de los Scripts](#descripci√≥n-de-los-scripts)
- [Requisitos](#requisitos)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Uso](#uso)
- [Formato de Datos](#formato-de-datos)
- [Landmarks de MediaPipe](#landmarks-de-mediapipe)
- [Soluci√≥n de Problemas](#soluci√≥n-de-problemas)

---

## Descripci√≥n de los Scripts
El proyecto cuenta con dos herramientas principales seg√∫n el nivel de datos requerido:

**1. ```getdata_rsp.py``` (B√°sico):**
- **Enfoque:** Visi√≥n artificial pura.
- **Captura:** Im√°genes RGB (.jpg) y coordenadas de la mano (.csv).
- **Ideal para:** Modelos de clasificaci√≥n de im√°genes o redes neuronales basadas en puntos clave (landmarks).

**2. ```dataset_creator_myo.py``` (Avanzado - Multimodal):**
- **Enfoque:** Fusi√≥n de sensores.
- **Captura:** Im√°genes + Landmarks + Datos EMG (electromiograf√≠a) + Datos IMU (aceler√≥metro, giroscopio y orientaci√≥n).
- **Sincronizaci√≥n:** Utiliza un sistema de hilos para capturar una "ventana" de datos del brazalete alrededor del momento de la foto.
- **Ideal para:** Modelos h√≠bridos que combinan visi√≥n con se√±ales musculares y de movimiento.

## Requisitos

#### Software
- Python 3.11.9
- Webcam funcional
- MYO Armband SDK
- Sistema operativo: Windows, macOS, o Linux

**Archivo `requirements.txt`:**
```
mediapipe>=0.10.21
opencv-python==4.11.0.86
numpy==1.23.5
```

---

## Estructura del Proyecto

```
Getdata/
‚îÇ
‚îú‚îÄ‚îÄ getdata_rsp.py              # Script solo RGB y landmarks
‚îú‚îÄ‚îÄ dataset_creator_myo.py      # Script Multimodal (RGB + EMG + IMU)
‚îú‚îÄ‚îÄ MYO_armband_SDK/            # Carpeta con el SDK oficial de Myo
‚îî‚îÄ‚îÄ dataset/                    # Generado autom√°ticamente
    ‚îú‚îÄ‚îÄ images/                 # Im√°genes (Rock/Paper/Scissors/None)
    ‚îú‚îÄ‚îÄ landmarks/              # CSV de puntos clave y archivos JSON de metadata
    ‚îú‚îÄ‚îÄ emg/                    # CSV con los 8 canales de se√±ales musculares (solo Myo)
    ‚îî‚îÄ‚îÄ imu/                    # CSV con orientaci√≥n y aceleraci√≥n (solo Myo)
```

---

## Uso

#### Ejecutar el programa

Para iniciar la captura, elige el script seg√∫n tu hardware disponible:
```bash
# Opci√≥n A: Solo c√°mara
python getdata_rsp.py 

# Opci√≥n B: C√°mara + Myo Armband conectado
python dataset_creator_myo.py
```

#### Controles del Teclado

| Tecla | Funci√≥n |
|-------|---------|
| `1` | Modo ROCK (piedra) |
| `2` | Modo PAPER (papel) |
| `3` | Modo SCISSORS (tijeras) |
| `4` | Modo NONE (sin gesto) |
| `ESPACIO` | Iniciar/Pausar captura autom√°tica |
| `S` | Capturar imagen individual |
| `D` | **ELIMINAR TODO** el dataset |
| `Q` | Salir del programa de forma segura|

---

## Formato de Datos

#### Im√°genes y Landmarks (Ambos scripts)
- **Im√°genes:** JPG 640x480 sin marcas de dibujo para entrenamiento limpio.
- **Landmarks:** Archivos CSV con 21 puntos (x, y, z) mapeados por MediaPipe.

#### Datos de Sensores (Solo dataset_creator_myo.py)
- **EMG:** Archivo CSV por muestra con los valores de los 8 sensores del brazalete.
- **IMU:** Datos de aceleraci√≥n, giroscopio y cuaterniones de orientaci√≥n.
- **Metadata (JSON):** Archivo que vincula todos los componentes (imagen, emg, imu) de una misma muestra para facilitar el entrenamiento multimodal.

---

## Landmarks de MediaPipe

El sistema detecta **21 puntos** clave por mano, permitiendo entender la estructura √≥sea del gesto:

| √çndice | Nombre | Descripci√≥n | 
|--------|--------|-------------|
| 0 |  WRIST | Mu√±eca (Punto base) | 
| 4, 8, 12, 16, 20 |  TIPS | Puntas de los dedos (Pulgar a Me√±ique) | 
| 5, 9, 13, 17 | MCP | Nudillos principales | 

#### Estructura de la Mano
![Marcadores_Mano](imgs/hand-landmarks.png)

Derecha:
![Mano_der](imgs/der.png)

Izquierda:
![Mano_izq](imgs/izq.png)

---

## Recomendaciones para un Buen Dataset

**1. Frecuencia de captura:** El script multimodal tiene un intervalo de 2 segundos para permitir que el buffer de datos EMG se llene correctamente. No muevas la mano demasiado r√°pido.

**2. Calibraci√≥n Myo:** Aseg√∫rate de que el Myo est√© bien ajustado al antebrazo y "calentado" (conecta y espera a que los datos fluyan) antes de iniciar la captura masiva.

**3. Diversidad:** Captura gestos con la palma hacia arriba, hacia abajo y de lado.

#### Cantidad de Datos
- **M√≠nimo:** 100 im√°genes por clase
- **Recomendado:** 200-300 im√°genes por clase
- **√ìptimo:** 500+ im√°genes por clase

‚ùå **NO hacer:**
- Motion blur (movimientos muy r√°pidos)
- Mano parcialmente fuera del encuadre
- Dedos ocultos u ocluidos
- Iluminaci√≥n muy baja (mano no visible)

#### Balance del Dataset
Intenta tener un n√∫mero similar de im√°genes en cada clase:
```
Rock:     250 im√°genes
Paper:    240 im√°genes
Scissors: 260 im√°genes
None:     240 im√°genes (opcional)
```

---

## Soluci√≥n de Problemas

#### Error: "No module named 'mediapipe'"
```bash
pip install mediapipe opencv-python
```

#### Error: "Can't open camera"
- Verifica que tu webcam est√© conectada
- Cierra otras aplicaciones que usen la c√°mara (Zoom, Teams, etc.)
- En Linux, verifica permisos: `sudo usermod -a -G video $USER`

#### La mano no se detecta
- Mejora la iluminaci√≥n
- Acerca m√°s la mano a la c√°mara
- Aseg√∫rate de que toda la mano est√© visible
- Prueba con un fondo menos complejo

#### Im√°genes borrosas
- Reduce la velocidad de movimiento de la mano
- Mant√©n la mano m√°s estable
- Mejora la iluminaci√≥n

#### El programa est√° lento
- Cierra otras aplicaciones
- Verifica que tienes buena CPU (MediaPipe es intensivo)
- Reduce la resoluci√≥n en el c√≥digo si es necesario

---

### üìù Licencia

Este proyecto es de c√≥digo abierto para uso educativo y de investigaci√≥n.

---

**Creado para investigaci√≥n en Computer Vision y Deep Learning**
